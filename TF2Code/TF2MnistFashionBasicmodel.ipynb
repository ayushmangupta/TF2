{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2MnistFashionBasicmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushmangupta/TF2/blob/master/TF2MnistFashionBasicmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8SBkgUuSfeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3eb7c57f-0b52-48a8-a90a-84d3831735a3"
      },
      "source": [
        "\n",
        "!pip3 install tensorflow-gpu==2.0.0-beta1\n",
        "#!pip3 install tensorflow_datasets\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as tfk\n",
        "import numpy as np\n",
        "import tensorflow.keras.layers as tfkl\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "print(tf.__version__)\n",
        "log_dir = \"logd\"\n",
        "!rm -rf logd/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n",
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txWGIc0ySfeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(tfk.Model):\n",
        "  def __init__(self):\n",
        "    super(Model,self).__init__()\n",
        "    self.common_layers=[]\n",
        "    self.common_layers.append(tfkl.Conv2D(32,3,strides=(1,1),padding='same',activation=\"relu\",input_shape=(28,28,1)))\n",
        "    self.common_layers.append(tfkl.BatchNormalization())\n",
        "    self.common_layers.append(tfkl.MaxPool2D((2,2),(2,2)))\n",
        "    self.common_layers.append(tfkl.Conv2D(32,3,strides=(1,1),padding='same',activation=\"relu\"))\n",
        "    self.common_layers.append(tfkl.BatchNormalization())\n",
        "    self.common_layers.append(tfkl.MaxPool2D((2,2),(2,2)))\n",
        "    self.common_layers.append(tfkl.Dropout(0.2))\n",
        "    self.common_layers.append(tfkl.Conv2D(64,3,strides=(1,1),padding='same',activation=\"relu\"))\n",
        "    self.common_layers.append(tfkl.BatchNormalization())\n",
        "    self.common_layers.append(tfkl.MaxPool2D((2,2),(2,2)))\n",
        "    self.common_layers.append(tfkl.Conv2D(64,3,strides=(1,1),padding='same',activation=\"relu\"))\n",
        "    self.common_layers.append(tfkl.BatchNormalization())\n",
        "    self.common_layers.append(tfkl.MaxPool2D((2,2),(2,2)))\n",
        "    self.common_layers.append(tfkl.Dropout(0.2))\n",
        "    self.common_layers.append(tfkl.Flatten())\n",
        "    self.common_layers.append(tfkl.Dense(512,activation=\"relu\"))\n",
        "    self.common_layers.append(tfkl.Dropout(0.2))\n",
        "    self.common_layers.append(tfkl.Dense(32,activation=\"relu\"))\n",
        "    self.common_layers.append(tfkl.Dense(10,activation=\"softmax\"))\n",
        "                              \n",
        "  def call(self,x):\n",
        "    x= tf.convert_to_tensor(x,dtype=tf.float32)\n",
        "    for layer in self.common_layers:\n",
        "      x = layer(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aCDr21nSfeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_filters(model,ii):\n",
        "    d = model.layers[0]\n",
        "    o = d(ii)\n",
        "    mainImg=[]\n",
        "    for i in range(8): \n",
        "        a = []\n",
        "        for j in range(8):\n",
        "            a.append(o[i,:,:,j])\n",
        "        imgg = np.hstack(a)\n",
        "        mainImg.append(imgg)\n",
        "    return np.vstack(mainImg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ApSbe9oSfeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7b1b8649-93b1-457e-d065-ef33b276c3e7"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = tf.cast(x_train,tf.float32)\n",
        "x_test = tf.cast(x_test,tf.float32)\n",
        "\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsBXIqUVSfec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ii = x_train[:10,:,:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o3yLkcRSfeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe2m4wypSfem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWgrOTuZSfer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model()\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "test_log_dir = 'logd/gradient_tape/' + current_time + '/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdrK9aE9Sfex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0usrBURSfe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "862b5c5d-7718-4ad4-82a9-256d75262ce4"
      },
      "source": [
        "EPOCHS = 15\n",
        "#tf.summary.trace_on(graph=True, profiler=True)\n",
        "for epoch in range(EPOCHS):\n",
        "    for images, labels in train_ds:\n",
        "        train_step(images, labels)\n",
        "    \n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "      test_step(test_images, test_labels)\n",
        "\n",
        "    with test_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "        filter_img = plot_filters(model,ii)\n",
        "        filter_img = tf.summary.image('image',filter_img[np.newaxis,:,:,np.newaxis],step=epoch)\n",
        "        #tf.summary.trace_export(name=\"my_func_trace\", step=0, profiler_outdir=train_log_dir)\n",
        "        \n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print (template.format(epoch+1,\n",
        "                           train_loss.result(),\n",
        "                           train_accuracy.result()*100,\n",
        "                           test_loss.result(),\n",
        "                           test_accuracy.result()*100))\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.5259063839912415, Accuracy: 80.375, Test Loss: 0.3490198254585266, Test Accuracy: 86.52999877929688\n",
            "Epoch 2, Loss: 0.4142681956291199, Accuracy: 84.57333374023438, Test Loss: 0.30363813042640686, Test Accuracy: 88.7300033569336\n",
            "Epoch 3, Loss: 0.3610939681529999, Accuracy: 86.55611419677734, Test Loss: 0.30649441480636597, Test Accuracy: 89.31000518798828\n",
            "Epoch 4, Loss: 0.3269927501678467, Accuracy: 87.83333587646484, Test Loss: 0.31819021701812744, Test Accuracy: 88.94000244140625\n",
            "Epoch 5, Loss: 0.30234432220458984, Accuracy: 88.7509994506836, Test Loss: 0.33387187123298645, Test Accuracy: 88.94000244140625\n",
            "Epoch 6, Loss: 0.28294822573661804, Accuracy: 89.46694946289062, Test Loss: 0.31026577949523926, Test Accuracy: 90.09000396728516\n",
            "Epoch 7, Loss: 0.2667304575443268, Accuracy: 90.07714080810547, Test Loss: 0.2997649312019348, Test Accuracy: 90.4000015258789\n",
            "Epoch 8, Loss: 0.2533303499221802, Accuracy: 90.58125305175781, Test Loss: 0.3071303963661194, Test Accuracy: 90.44999694824219\n",
            "Epoch 9, Loss: 0.24140003323554993, Accuracy: 91.02574157714844, Test Loss: 0.32252293825149536, Test Accuracy: 90.7699966430664\n",
            "Epoch 10, Loss: 0.23108898103237152, Accuracy: 91.40666961669922, Test Loss: 0.3076300621032715, Test Accuracy: 91.14999389648438\n",
            "Epoch 11, Loss: 0.22156259417533875, Accuracy: 91.75711822509766, Test Loss: 0.33408892154693604, Test Accuracy: 90.6500015258789\n",
            "Epoch 12, Loss: 0.21314309537410736, Accuracy: 92.06958770751953, Test Loss: 0.37935110926628113, Test Accuracy: 90.31999969482422\n",
            "Epoch 13, Loss: 0.20537035167217255, Accuracy: 92.35679626464844, Test Loss: 0.38418132066726685, Test Accuracy: 89.99000549316406\n",
            "Epoch 14, Loss: 0.19842879474163055, Accuracy: 92.61488342285156, Test Loss: 0.41369330883026123, Test Accuracy: 89.86000061035156\n",
            "Epoch 15, Loss: 0.19174771010875702, Accuracy: 92.86189270019531, Test Loss: 0.4421047270298004, Test Accuracy: 89.6300048828125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JlRyaZMSffA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}